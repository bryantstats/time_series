---
title: "Time Series Project"
format: 
  html: 
    toc: true
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, eval = FALSE)
```

------------------------------------------------------------------------

*Instruction:*

-   *In this project, you are asked to work with a time series of your choice.  This series should not be the same as the series we have used in the class.*

-   *The structure of the project is as follows. Address all of the questions raised in the Your answers will be either in text (For example: there is question on commenting on the trend of the series or question on explaining the main idea of moving average) and codes (which you can use the sample codes to answer).*

-   *The sample codes for the series can be found at links below. All the codes in this project should be available on the sample codes.*

      [Sample codes 1](project_ts_codes.html)
      
      [Sample codes 2](project_ts_codes2.html)
      
      [Sample codes 3](project_ts_codes3.html)

-   *Organize your answers (text and codes) in an Rmarkdow or Quarto then knit it to a Word document. You can find an sample Rmarkdown(.Rmd) and Quarto(.qmd) at the links below.* 

      [Rmarkdown](project_ts_sample.Rmd) 

      [Quarto](project_ts_sample.qmd)

- *Submit the Word document to Canvas.*

------------------------------------------------------------------------

## 1. Data Exploration

-   Describe your time series and the source of the series. 

-   Import the series. Note: Make sure you specify the correct starting time and frequency for the series.

-   Plot the time series.

-   Comment on the trend of the series (does the series have trend? upward or downward? from when to when, etc).

-   Comment on the seasonality of the series (does the series have seasonal component? if so, what is the seasonal period, etc.)

-   Comment on the seasonality of the series. Notice that trend or seasonal series is not stationary, being stationary implying having constant variance and constant mean.

```{r}
library(TTR)
library(forecast)
df <- read.csv("Amtrak data.csv")
y <- ts(df$Ridership, start = c(1991,1), end = c(2004, 3), freq = 12)
plot(y, xlab = "Time", ylab = "Ridership")
```

### 1.1 Smoothing

-   *Moving Average*: Explain the main idea of Moving average. Apply the MA method on the series. Plot the original series and its MA smoothing. Try a few different moving average $k$ and comment on the trend of the series through the smoothing curve. What values of $k$ best reveal the series pattern?

```{r}
plot(y, xlab = "Time", ylab = "Ridership")

# create a moving average series
k = 16  # set the moving average 
y_sma = SMA(y, n = k)

# plot the moving average series
lines(y_sma, col = "red")
```

-   *Exponential Smoothing* (ES): Explain the main idea of exponential smoothing. Apply the ES method on the series. Plot the original series and its ES smoothing. Try a few different weights comment on the trend of the series through the smoothing curve. What values of the weight best reveal the series' pattern? Compare the ES curve and the MA curve above.

```{r}
plot(y, xlab = "Time", ylab = "Ridership")

# create a moving average series
w = .7

y_ema = EMA(y, ratio = 1-w)


# plot the moving average series
lines(y_ema, col = "red")
```

### 1.2 Decomposition

-   *Classical Decomposition*. Explain the idea of Classical Decomposition in your own words. Apply the classical decomposition on the series for additive model and multiplicative model.

```{r}
ourDecomposition <- decompose(y, type="additive")
plot(ourDecomposition)
```

```{r}
ourDecomposition <- decompose(y, type="multiplicative")
plot(ourDecomposition)
```

-   *STL Decomposition*. Explain the idea of STL Decomposition in your own words. What is the main difference between the classical decomposition and STL Decomposition. Apply STL Decomposition on the series.

```{r}
ourDecomposition <- stl(y, s.window = "periodic")
plot(ourDecomposition)
```

### 1.3 Auto-correltion

-   Explain what the Auto-correlation Function (ACF) is and plot the ACF of the series. What is the first value of the ACF (ACF when the lag is 0) Is the series stationary according to the look of the ACF?

```{r}
acf(y)
```

-   Explain what the Partial Auto-correlation Function (PACF) is and plot the PACF of the series.

```{r}
pacf(y)
```

## 2. Modelling

In addition some baseline models, We will consider two models the HoltWinters and the ARIMA models. The baseline models are

-   Mean/Average model: forecast by the average of the training series

-   Naive Model: forecast by the last observation of the series

-   Seasonal Naive Model: forecast by the values of the last season

-   Random Walk with drift Model: Drawing the line from the first to the last observation

To evaluate the models, We will use a machine learning approach, which is use a portion of the data for training and the remainder data for testing. We also perform residual analysis for the models.

### 2.1 Model Training

Follow the sample codes to.

-   Split the original series into the training series and the testing series

-   Train all six models

```{r}
# data partition
nValid <- 36
nTrain <- length(y) - nValid
train.ts <- window(y, start = c(1991, 1), end = c(1991, nTrain))
valid.ts <- window(y, start = c(1991, nTrain + 1), end = c(1991, nTrain + nValid))

# Modeling

#basic models

# average method: forecast by the average of the training series
model1 = meanf(train.ts, h = nValid, level = 0)

# naive: forecast by the last observation of the series
model2 = naive(train.ts, h = nValid, level = 0)

# seasonal naive: forecast by the last season
model3 = snaive(train.ts, h = nValid, level = 0)

# drift: drawing the line from the first to the last observation
model4 = rwf(train.ts, h = nValid, level = 0, drift = TRUE)



# more advanced model
model5 = HoltWinters(train.ts, alpha=TRUE, 
                            beta=TRUE, 
                            gamma=TRUE)
model6 = auto.arima(train.ts)

```

### 2.2 Residual Analysis

A `good` model would have residuals looks like white-noise of a mean zero normal distribution, which means

-   The residuals should have no autocorrelation.
-   The residuals should have a mean zero
-   The residuals should have constant variance
-   The residuals should be normally distributed

Report the residuals analysis of all the models. Which model would you consider `good` models? Some indications of a `good` model could be

- The ACF is within the blue strip
- The distribution of the residual follows a bell curve
- The p-value of the Ljung-Box test is large

```{r}
checkresiduals(model1)
checkresiduals(model2)
checkresiduals(model3)
checkresiduals(model4)
checkresiduals(model5)
checkresiduals(model6)
```

### 2.3 Testing Accuracy

-   Calculate the forecast of all the models on the validation period. Calculate the Mean absolute percentage error (MAPE) of all the models. Plot the forecast of all models.  

- Which model gives the lowest MAPE? Which model gives the greatest MAPE?

```{r}
# forecasting
forecast1 = forecast(model1, h = nValid, level = 0)
forecast2 = forecast(model2, h = nValid, level = 0)
forecast3 = forecast(model3, h = nValid, level = 0)
forecast4 = forecast(model4, h = nValid, level = 0)
forecast5 = forecast(model5, h = nValid, level = 0)
forecast6 = forecast(model6, h = nValid, level = 0)

# plotting forecast
plot(forecast1)
lines(valid.ts, col = 'red')
plot(forecast2)
lines(valid.ts, col = 'red')
plot(forecast3)
lines(valid.ts, col = 'red')
plot(forecast4)
lines(valid.ts, col = 'red')
plot(forecast5)
lines(valid.ts, col = 'red')
plot(forecast6)
lines(valid.ts, col = 'red')


# accuracy
a1 = accuracy(forecast1$mean, valid.ts)
a2 = accuracy(forecast2$mean, valid.ts)
a3 = accuracy(forecast3$mean, valid.ts)
a4 = accuracy(forecast4$mean, valid.ts)
a5 = accuracy(forecast5$mean, valid.ts)
a6 = accuracy(forecast6$mean, valid.ts)

rbind(a1, a2, a3,a4, a5, a6)
```

## 3. Forecasting

Based on the MAPE above, decide the selected model. Retrain the best model on the entire series. Use the retrained model to forecast the next values. Plot the series and the forecast values.

```{r}
# the arima model gives the lowest MAPE, 
# so we will select this model as the final model 
# to train it on the entire dataset to make forecasting.

selected_model =  arima(y)
new_forecast = forecast(selected_model)
plot(new_forecast)
```

------------------------------------------------------------------------